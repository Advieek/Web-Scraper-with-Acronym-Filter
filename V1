import requests
from bs4 import BeautifulSoup
import re

def extract_text_from_website(url, html_tag):
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    main_content = soup.find(html_tag)
    return main_content.get_text() if main_content else ""

def extract_acronyms(text):
    # This regex pattern looks for words with 2 or more capital letters
    acronyms = re.findall(r'\b[A-Z]{2,}\b', text)
    return sorted(set(acronyms))  # Remove duplicates and sort

def main():
    url = input("Enter the website URL: ")
    html_tag = input("Enter the HTML tag for the main content (e.g., 'div', 'article', 'main'): ")
    
    extracted_text = extract_text_from_website(url, html_tag)
    
    if not extracted_text:
        print("Failed to extract text from the website.")
        return
    
    acronyms = extract_acronyms(extracted_text)
    
    with open('extracted_text.txt', 'w', encoding='utf-8') as f:
        f.write(extracted_text)
    
    with open('acronyms.txt', 'w', encoding='utf-8') as f:
        for i, acronym in enumerate(acronyms, 1):
            f.write(f"{i}. {acronym}\n")
    
    print("Extraction complete. Check 'extracted_text.txt' for the full text and 'acronyms.txt' for the list of acronyms.")

if __name__ == "__main__":
    main()
